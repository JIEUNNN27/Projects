{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef020b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03791281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10013acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #GPU 설정 할 때마다 쓸 지피유로 변경\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2, 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36fc3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#새로운버젼2\n",
    "class SFCN(nn.Module):\n",
    "    def __init__(self, channel_number=[32, 64, 128, 256, 256, 64], output_dim=1, dropout=True):\n",
    "        super(SFCN, self).__init__()\n",
    "        n_layer = len(channel_number)\n",
    "        self.feature_extractor = nn.Sequential()\n",
    "        for i in range(n_layer):\n",
    "            if i == 0:\n",
    "                in_channel = 1\n",
    "            else:\n",
    "                in_channel = channel_number[i-1]\n",
    "            out_channel = channel_number[i]\n",
    "            if i < n_layer-1:\n",
    "                self.feature_extractor.add_module('conv_%d' % i,\n",
    "                                                  self.conv_layer(in_channel,\n",
    "                                                                  out_channel,\n",
    "                                                                  maxpool=True,\n",
    "                                                                  kernel_size=3,\n",
    "                                                                  padding=1))\n",
    "            else:\n",
    "                self.feature_extractor.add_module('conv_%d' % i,\n",
    "                                                  self.conv_layer(in_channel,\n",
    "                                                                  out_channel,\n",
    "                                                                  maxpool=False,\n",
    "                                                                  kernel_size=1,\n",
    "                                                                  padding=0))\n",
    "        avg_shape = [5, 6, 5]\n",
    "        self.classifier = nn.Sequential()\n",
    "        self.classifier.add_module('average_pool', nn.AvgPool3d(avg_shape))\n",
    "        if dropout is True:\n",
    "            self.classifier.add_module('dropout', nn.Dropout(0.5))\n",
    "        i = n_layer\n",
    "        in_channel = channel_number[-1]\n",
    "        out_channel = output_dim  \n",
    "        self.classifier.add_module('last_conv',\n",
    "                                   nn.Conv3d(in_channel, out_channel, padding=0, kernel_size=1))\n",
    "        \n",
    "        self.final_fc = nn.Linear(1, output_dim)\n",
    "\n",
    "    @staticmethod\n",
    "    def conv_layer(in_channel, out_channel, maxpool=True, kernel_size=3, padding=0, maxpool_stride=2):\n",
    "        if maxpool is True:\n",
    "            layer = nn.Sequential(\n",
    "                nn.Conv3d(in_channel, out_channel, padding=padding, kernel_size=kernel_size),\n",
    "                nn.BatchNorm3d(out_channel),\n",
    "                nn.MaxPool3d(2, stride=maxpool_stride),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            layer = nn.Sequential(\n",
    "                nn.Conv3d(in_channel, out_channel, padding=padding, kernel_size=kernel_size),\n",
    "                nn.BatchNorm3d(out_channel),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        return layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_f = self.feature_extractor(x)\n",
    "        x = self.classifier(x_f)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.sigmoid(self.final_fc(x))  # Add sigmoid activation function\n",
    "        x = x * 70 + 20  # Scale the output between 20 and 90\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cbce72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data_dir, csv_file, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_info = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data_dir, f\"{self.data_info.iloc[idx, 0]}_T1w_restore_brain.nii.gz\")\n",
    "        image = nib.load(img_name).get_fdata()\n",
    "\n",
    "        # 이미지를 3D로 변환 (첫 번째 차원 추가)\n",
    "        image = image[np.newaxis]\n",
    "\n",
    "        # 문자열로 저장되어 있는 나이 정보를 숫자로 변환\n",
    "        age = float(self.data_info.iloc[idx, 1])\n",
    "        \n",
    "        subject_id = self.data_info.iloc[idx, 0]  # Subject ID 가져오기\n",
    "        gender = self.data_info.iloc[idx, 2]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, age, gender, subject_id  # Subject ID와 Gender 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e65d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataScaler(object):\n",
    "    def __call__(self, image):\n",
    "        image = image / image.mean()  # 평균으로 스케일링\n",
    "        image = torch.tensor(image, dtype=torch.float32)  # 이미지를 텐서로 변환\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78dd09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이거 새로 정의한거\n",
    "def mean_absolute_error(y_pred, y_true):\n",
    "    y_true = y_true.to(y_pred.device)  # y_true도 y_pred와 동일한 device로 이동\n",
    "    return torch.mean(torch.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e25bbb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# GPU 설정\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2abddea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩 및 전처리\n",
    "data_folder = '../hcp_ya/ya_resize'\n",
    "csv_file = 'subject_age_gender.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02076765",
   "metadata": {},
   "source": [
    "데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d2d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리를 위한 변환기 적용\n",
    "transform = transforms.Compose([DataScaler()])\n",
    "dataset = MRIDataset(data_folder, csv_file, transform=transform)\n",
    "\n",
    "# 데이터를 train, val 세트로 나누기\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# DataLoader 설정\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64949ad",
   "metadata": {},
   "source": [
    "test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4b184c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "transform = transforms.Compose([DataScaler()])\n",
    "test_data_folder = 'test' #테스트nii.gz 있는 경로\n",
    "test_csv_file = 'test.csv' #테스트 csv 파일 경로\n",
    "# 따로 준비한 Test 데이터 로딩\n",
    "test_dataset = MRIDataset(test_data_folder, test_csv_file, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3c950ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 11.29 GiB already allocated; 0 bytes free; 11.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 모델 초기화\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSFCN\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#model = torch.nn.DataParallel(model, device_ids=[2, 3])  # 여러 GPU에서 모델을 병렬로 실행하도록 설정합니다.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 가중치 로드하기\u001b[39;00m\n\u001b[0;32m      6\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_20190719_00_epoch_best_mae.p\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 가중치 파일 경로\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    924\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    924\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 11.29 GiB already allocated; 0 bytes free; 11.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "model = SFCN(output_dim=1).to(device)\n",
    "#model = torch.nn.DataParallel(model, device_ids=[2, 3])  # 여러 GPU에서 모델을 병렬로 실행하도록 설정합니다.\n",
    "\n",
    "# 가중치 로드하기\n",
    "path = \"run_20190719_00_epoch_best_mae.p\"  # 가중치 파일 경로\n",
    "pretrained_dict = torch.load(path, map_location=device)\n",
    "\n",
    "# 모델의 state_dict 가져오기\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# 모델과 가중치 사이즈 맞추기\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and v.size() == model_dict[k].size()}\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #이거 더 적게 해보기\n",
    "\n",
    "best_val_loss = float('inf')  # 최고의 검증 손실 값을 저장하기 위한 변수 초기화\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77383083",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: \", leave=False):\n",
    "    #for batch in train_loader:\n",
    "        inputs = batch[0].to(device)\n",
    "        labels = torch.tensor(batch[1], dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = mean_absolute_error(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0.0\n",
    "        for val_batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: \", leave=False):\n",
    "        #for val_batch in val_loader:\n",
    "            val_inputs = val_batch[0].to(device)\n",
    "            val_labels = torch.tensor(val_batch[1], dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss = mean_absolute_error(val_outputs, val_labels)\n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # 가중치 저장 (Validation Loss가 가장 낮을 때에만 저장)\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"sfcn.p\")\n",
    "            print(\"Best model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece51eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = []\n",
    "true_ages = []\n",
    "predicted_ages = []\n",
    "genders = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_test_loss = 0.0\n",
    "    for test_batch in test_loader:\n",
    "        for i in range(test_batch[0].size(0)):\n",
    "            test_input = test_batch[0][i].unsqueeze(0).to(device)\n",
    "            test_label = torch.tensor([test_batch[1][i]], dtype=torch.float32).unsqueeze(1).to(device)\n",
    "            test_subject_id = test_batch[2][i]\n",
    "            test_gender = test_batch[3][i]\n",
    "\n",
    "            test_output = model(test_input)\n",
    "            test_loss = mean_absolute_error(test_output, test_label)\n",
    "            total_test_loss += test_loss.item()\n",
    "\n",
    "            # Append subject ID, true age, predicted age, and gender to the lists\n",
    "            subject_ids.append(test_subject_id)\n",
    "            true_ages.append(test_label.item())\n",
    "            predicted_ages.append(test_output.item())  # Change this line\n",
    "            genders.append(test_gender)\n",
    "            \n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "with open(\"run_20190719_00_epoch_best_mae.csv\", mode=\"w\", newline=\"\") as file:\n",
    "    fieldnames = [\"SubjectID\", \"TrueAge\", \"PredictedAge\", \"Gender\"]\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    for subject, true_age, predicted_age, gender in zip(subject_ids, true_ages, predicted_ages, genders):\n",
    "        # If subject is stored as (Tensor) in the list of test_subject_ids,\n",
    "        # convert the subject to string and remove \"tensor\" from the Subject ID\n",
    "        if isinstance(subject, torch.Tensor):\n",
    "            subject = subject.item()\n",
    "        \n",
    "        # Extract the predicted age value\n",
    "        predicted_age_scalar = predicted_age\n",
    "        \n",
    "        writer.writerow({\"SubjectID\": gender, \"TrueAge\": true_age, \"PredictedAge\": predicted_age_scalar, \"Gender\": subject})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96b961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
